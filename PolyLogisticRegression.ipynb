{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6QwYd9ZwFFqS5fJEDp61t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DucBox/Hw_AI/blob/main/PolyLogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJjSJaWz1Zjv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "#  Class PolynomialRegression\n",
        "#-----------------------------------------------------------------\n",
        "\n",
        "class PolynomialRegression:\n",
        "\n",
        "    def __init__(self, degree=1, regLambda=1E-8):\n",
        "        '''\n",
        "        Constructor\n",
        "        '''\n",
        "        self.degree = degree\n",
        "        self.regLambda = regLambda\n",
        "        self.theta = None  # Parameters will be stored here after training\n",
        "\n",
        "    def polyfeatures(self, X, degree):\n",
        "        '''\n",
        "        Expands the given X into an n * d array of polynomial features of\n",
        "            degree d.\n",
        "\n",
        "        Returns:\n",
        "            A n-by-d numpy array, with each row comprising of\n",
        "            X, X * X, X ** 3, ... up to the dth power of X.\n",
        "            Note that the returned matrix will not include the zero-th power.\n",
        "\n",
        "        Arguments:\n",
        "            X is an n-by-1 column numpy array\n",
        "            degree is a positive integer\n",
        "        '''\n",
        "        n = len(X)\n",
        "        features = np.zeros((n, degree))\n",
        "        for d in range(1, degree + 1):\n",
        "            features[:, d - 1] = np.power(X, d).flatten()\n",
        "        return features\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Trains the model\n",
        "        Arguments:\n",
        "            X is a n-by-1 array\n",
        "            y is an n-by-1 array\n",
        "        Returns:\n",
        "            No return value\n",
        "        Note:\n",
        "            You need to apply polynomial expansion and scaling\n",
        "            at first\n",
        "        '''\n",
        "        X_poly = self.polyfeatures(X, self.degree)\n",
        "        n, d = X_poly.shape\n",
        "\n",
        "        # Add a column of ones to X_poly for the bias term\n",
        "        X_poly = np.column_stack((np.ones(n), X_poly))\n",
        "\n",
        "        # Regularized linear regression closed-form solution\n",
        "        reg_matrix = self.regLambda * np.eye(d + 1)\n",
        "        reg_matrix[0, 0] = 0  # No regularization for bias term\n",
        "\n",
        "        self.theta = np.linalg.inv(X_poly.T @ X_poly + reg_matrix) @ X_poly.T @ y\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Use the trained model to predict values for each instance in X\n",
        "        Arguments:\n",
        "            X is a n-by-1 numpy array\n",
        "        Returns:\n",
        "            an n-by-1 numpy array of the predictions\n",
        "        '''\n",
        "        X_poly = self.polyfeatures(X, self.degree)\n",
        "\n",
        "        # Add a column of ones to X_poly for the bias term\n",
        "        X_poly = np.column_stack((np.ones(len(X)), X_poly))\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = X_poly @ self.theta\n",
        "        return predictions\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "#  End of Class PolynomialRegression\n",
        "#-----------------------------------------------------------------\n",
        "\n",
        "def learningCurve(Xtrain, Ytrain, Xtest, Ytest, regLambda, degree):\n",
        "    '''\n",
        "    Compute learning curve\n",
        "\n",
        "    Arguments:\n",
        "        Xtrain -- Training X, n-by-1 matrix\n",
        "        Ytrain -- Training y, n-by-1 matrix\n",
        "        Xtest -- Testing X, m-by-1 matrix\n",
        "        Ytest -- Testing Y, m-by-1 matrix\n",
        "        regLambda -- regularization factor\n",
        "        degree -- polynomial degree\n",
        "\n",
        "    Returns:\n",
        "        errorTrains -- errorTrains[i] is the training accuracy using\n",
        "        model trained by Xtrain[0:(i+1)]\n",
        "        errorTests -- errorTrains[i] is the testing accuracy using\n",
        "        model trained by Xtrain[0:(i+1)]\n",
        "\n",
        "    Note:\n",
        "        errorTrains[0:1] and errorTests[0:1] won't actually matter, since we start displaying the learning curve at n = 2 (or higher)\n",
        "    '''\n",
        "\n",
        "    n = len(Xtrain)\n",
        "\n",
        "    errorTrain = np.zeros((n))\n",
        "    errorTest = np.zeros((n))\n",
        "    for i in range(2, n):\n",
        "        Xtrain_subset = Xtrain[:(i + 1)]\n",
        "        Ytrain_subset = Ytrain[:(i + 1)]\n",
        "        model = PolynomialRegression(degree, regLambda)\n",
        "        model.fit(Xtrain_subset, Ytrain_subset)\n",
        "\n",
        "        predictTrain = model.predict(Xtrain_subset)\n",
        "        err = predictTrain - Ytrain_subset\n",
        "        errorTrain[i] = np.multiply(err, err).mean()\n",
        "\n",
        "        predictTest = model.predict(Xtest)\n",
        "        err = predictTest - Ytest\n",
        "        errorTest[i] = np.multiply(err, err).mean()\n",
        "\n",
        "    return (errorTrain, errorTest)"
      ]
    }
  ]
}