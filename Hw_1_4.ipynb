{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCpB5djEUvRDcTFshL5DZu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DucBox/Hw_AI/blob/main/Hw_1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IN-E6JvMYjlj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluatePerformance():\n",
        "    '''\n",
        "    Evaluate the performance of decision trees,\n",
        "    averaged over 100 trials of 10-fold cross-validation\n",
        "\n",
        "    Return:\n",
        "      a matrix giving the performance that will contain the following entries:\n",
        "      stats[0,0] = mean accuracy of decision tree\n",
        "      stats[0,1] = std deviation of decision tree accuracy\n",
        "      stats[1,0] = mean accuracy of decision stump\n",
        "      stats[1,1] = std deviation of decision stump accuracy\n",
        "      stats[2,0] = mean accuracy of 3-level decision tree\n",
        "      stats[2,1] = std deviation of 3-level decision tree accuracy\n",
        "\n",
        "    ** Note that your implementation must follow this API**\n",
        "    '''\n",
        "\n",
        "    # Load Data\n",
        "    filename = '/content/SPECTF.dat'\n",
        "    data = np.loadtxt(filename, delimiter=',')\n",
        "    X = data[:, 1:]\n",
        "    y = np.array([data[:, 0]]).T\n",
        "    n, d = X.shape\n",
        "\n",
        "    # shuffle the data\n",
        "    idx = np.arange(n)\n",
        "    np.random.seed(13)\n",
        "    np.random.shuffle(idx)\n",
        "    X = X[idx]\n",
        "    y = y[idx]\n",
        "\n",
        "    # Initialize variables for collecting results\n",
        "    decision_tree_accuracies = []\n",
        "    decision_stump_accuracies = []\n",
        "    dt3_accuracies = []\n",
        "\n",
        "    # Additional decision trees of varying limited depths\n",
        "    dt_depth_accuracies = {2: [], 4: [], 6: []}\n",
        "\n",
        "    # Initialize learning curve variables\n",
        "    learning_curve_means = np.zeros((10, 4))\n",
        "    learning_curve_stddevs = np.zeros((10, 4))\n",
        "\n",
        "    # 100 trials of 10-fold cross-validation\n",
        "    for _ in range(100):\n",
        "        for i in range(10):\n",
        "            # Split the data into train and test folds\n",
        "            start = i * (n // 10)\n",
        "            end = (i + 1) * (n // 10)\n",
        "\n",
        "            Xtest = X[start:end, :]\n",
        "            ytest = y[start:end, :]\n",
        "\n",
        "            for j in range(1, 11):\n",
        "                # Use j% of the training data\n",
        "                train_size = int(j * 0.1 * (n - n // 10))\n",
        "                Xtrain = X[:train_size, :]\n",
        "                ytrain = y[:train_size, :]\n",
        "\n",
        "                # Train the decision tree\n",
        "                clf = tree.DecisionTreeClassifier()\n",
        "                clf = clf.fit(Xtrain, ytrain)\n",
        "\n",
        "                # Output predictions on the test fold\n",
        "                y_pred = clf.predict(Xtest)\n",
        "\n",
        "                # Compute accuracy for the decision tree\n",
        "                acc_decision_tree = accuracy_score(ytest, y_pred)\n",
        "                decision_tree_accuracies.append(acc_decision_tree)\n",
        "\n",
        "                learning_curve_means[j-1, 0] += acc_decision_tree\n",
        "                learning_curve_stddevs[j-1, 0] += acc_decision_tree ** 2\n",
        "\n",
        "                # Train the decision stump\n",
        "                clf_stump = tree.DecisionTreeClassifier(max_depth=1)\n",
        "                clf_stump = clf_stump.fit(Xtrain, ytrain)\n",
        "\n",
        "                # Output predictions on the test fold\n",
        "                y_pred_stump = clf_stump.predict(Xtest)\n",
        "\n",
        "                # Compute accuracy for decision stump\n",
        "                acc_decision_stump = accuracy_score(ytest, y_pred_stump)\n",
        "                decision_stump_accuracies.append(acc_decision_stump)\n",
        "\n",
        "                learning_curve_means[j-1, 1] += acc_decision_stump\n",
        "                learning_curve_stddevs[j-1, 1] += acc_decision_stump ** 2\n",
        "\n",
        "                # Train the 3-level decision tree\n",
        "                clf_dt3 = tree.DecisionTreeClassifier(max_depth=3)\n",
        "                clf_dt3 = clf_dt3.fit(Xtrain, ytrain)\n",
        "\n",
        "                # Output predictions on the test fold\n",
        "                y_pred_dt3 = clf_dt3.predict(Xtest)\n",
        "\n",
        "                # Compute accuracy for 3-level decision tree\n",
        "                acc_dt3 = accuracy_score(ytest, y_pred_dt3)\n",
        "                dt3_accuracies.append(acc_dt3)\n",
        "\n",
        "                learning_curve_means[j-1, 2] += acc_dt3\n",
        "                learning_curve_stddevs[j-1, 2] += acc_dt3 ** 2\n",
        "\n",
        "                # Train additional decision trees of varying limited depths\n",
        "                for depth in [2, 4, 6, 8, 10]:\n",
        "                    if depth not in dt_depth_accuracies:\n",
        "                      dt_depth_accuracies[depth] = []\n",
        "                    clf_depth = tree.DecisionTreeClassifier(max_depth=depth)\n",
        "                    clf_depth = clf_depth.fit(Xtrain, ytrain)\n",
        "\n",
        "                    # Output predictions on the test fold\n",
        "                    y_pred_depth = clf_depth.predict(Xtest)\n",
        "\n",
        "                    # Compute accuracy for the additional decision trees\n",
        "                    acc_depth = accuracy_score(ytest, y_pred_depth)\n",
        "                    dt_depth_accuracies[depth].append(acc_depth)\n",
        "\n",
        "                    learning_curve_means[j-1, 3] += acc_depth\n",
        "                    learning_curve_stddevs[j-1, 3] += acc_depth ** 2\n",
        "\n",
        "    # Compute mean and standard deviation for each classifier\n",
        "    meanDecisionTreeAccuracy = np.mean(decision_tree_accuracies) if decision_tree_accuracies else np.nan\n",
        "    stddevDecisionTreeAccuracy = np.std(decision_tree_accuracies) if decision_tree_accuracies else np.nan\n",
        "\n",
        "    meanDecisionStumpAccuracy = np.mean(decision_stump_accuracies) if decision_stump_accuracies else np.nan\n",
        "    stddevDecisionStumpAccuracy = np.std(decision_stump_accuracies) if decision_stump_accuracies else np.nan\n",
        "\n",
        "    meanDT3Accuracy = np.mean(dt3_accuracies) if dt3_accuracies else np.nan\n",
        "    stddevDT3Accuracy = np.std(dt3_accuracies) if dt3_accuracies else np.nan\n",
        "\n",
        "    # Compute mean and standard deviation for the learning curve\n",
        "    learning_curve_means /= 100\n",
        "    learning_curve_stddevs = np.sqrt(learning_curve_stddevs / 100 - learning_curve_means ** 2)\n",
        "\n",
        "    # Make certain that the return value matches the API specification\n",
        "    stats = np.zeros((3, 2))\n",
        "    stats[0, 0] = meanDecisionTreeAccuracy\n",
        "    stats[0, 1] = stddevDecisionTreeAccuracy\n",
        "    stats[1, 0] = meanDecisionStumpAccuracy\n",
        "    stats[1, 1] = stddevDecisionStumpAccuracy\n",
        "    stats[2, 0] = meanDT3Accuracy\n",
        "    stats[2, 1] = stddevDT3Accuracy\n",
        "\n",
        "    # Plot the learning curve\n",
        "    x_vals = np.arange(0.1, 1.1, 0.1)\n",
        "    plt.errorbar(x_vals, learning_curve_means[:, 0], yerr=learning_curve_stddevs[:, 0], label='Decision Tree')\n",
        "    plt.errorbar(x_vals, learning_curve_means[:, 1], yerr=learning_curve_stddevs[:, 1], label='Decision Stump')\n",
        "    plt.errorbar(x_vals, learning_curve_means[:, 2], yerr=learning_curve_stddevs[:, 2], label='3-level Decision Tree')\n",
        "    plt.errorbar(x_vals, learning_curve_means[:, 3], yerr=learning_curve_stddevs[:, 3], label='Depth-limited Decision Tree')\n",
        "\n",
        "    plt.xlabel('Percentage of Training Data')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Do not modify from HERE...\n",
        "if __name__ == \"__main__\":\n",
        "    stats = evaluatePerformance()\n",
        "    print(\"Decision Tree Accuracy = \", stats[0, 0], \" (\", stats[0, 1], \")\")\n",
        "    print(\"Decision Stump Accuracy = \", stats[1, 0], \" (\", stats[1, 1], \")\")\n",
        "    print(\"3-level Decision Tree = \", stats[2, 0], \" (\", stats[2, 1], \")\")\n",
        "# ...to HERE.\n"
      ],
      "metadata": {
        "id": "zU6MOTQHH29k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}